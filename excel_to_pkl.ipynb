{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Cell 1: \n",
    "working to import symptom data from an Excel file to csv\n",
    "\"\"\"\n",
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Source Excel on Cortex\n",
    "file_path = '/vol/cortex/cd3/pesaranlab/OCD_Mapping_Foundation/' \\\n",
    "            'sEEG_Pt_5_Symptom_provocation_wlabel.xlsx'\n",
    "print(\"Exists?\", os.path.exists(file_path))  # True\n",
    "\n",
    "# 2) Columns we care about\n",
    "time_cols   = ['Matlab Time', 'Timestamp']\n",
    "rating_cols = ['Obsessions','Compulsions','Anxiety','Energy','Depression','Distress']\n",
    "wanted      = time_cols + rating_cols\n",
    "\n",
    "# 3) Only these three sheets (days 3–5)\n",
    "sheets = ['Day3_02072025','Day4_02082025','Day5_02092025']\n",
    "\n",
    "for sheet in sheets:\n",
    "    # read with header on row 1, skip the blank row 2\n",
    "    df = pd.read_excel(\n",
    "        file_path,\n",
    "        sheet_name=sheet,\n",
    "        header=1,\n",
    "        skiprows=[2],\n",
    "    )\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # pick only the columns that exist\n",
    "    available = [c for c in wanted if c in df.columns]\n",
    "    if not available:\n",
    "        print(f\"⚠️  {sheet}: no matching columns found; skipping\")\n",
    "        continue\n",
    "\n",
    "    df2 = df[available].copy()\n",
    "\n",
    "    # 4) Convert literal \"missing\" → NaN in the rating columns\n",
    "    #    then drop rows where **all** ratings are NaN\n",
    "    ratings_present = [c for c in rating_cols if c in df2.columns]\n",
    "    df2[ratings_present] = df2[ratings_present].replace('missing', pd.NA)\n",
    "    df2 = df2.dropna(subset=ratings_present, how='all')\n",
    "\n",
    "    # 5) Write out a CSV for this day\n",
    "    out_path = (\n",
    "        '/vol/cortex/cd3/pesaranlab/OCD_Mapping_Foundation/'\n",
    "        f'{sheet}_filtered_symptom_data.csv'\n",
    "    )\n",
    "    df2.to_csv(out_path, index=False)\n",
    "    print(f\"Wrote {len(df2)} rows to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell 2: Extra scripts for filling in missing MATLAB time\n",
    "working to compute the correlation between MATLAB time and wall-clock time\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fn = \"Day3_02072025_filtered_symptom_data.csv\"\n",
    "\n",
    "# 1) Read everything as data (no header), skipping the first two lines \n",
    "#    if they contain sheet-name or bogus header info.\n",
    "df = pd.read_csv(fn, header=None, skiprows=2, usecols=[0,1], names=[\"mat_raw\",\"ts_raw\"])\n",
    "\n",
    "# 2) Extract the numeric MATLAB time\n",
    "df[\"mat_time\"] = df[\"mat_raw\"].astype(str).str.extract(r\"^(\\d+)\")[0].astype(float)\n",
    "\n",
    "# 3) Parse the timestamp into seconds since midnight\n",
    "ts = pd.to_datetime(df[\"ts_raw\"], format=\"%H:%M:%S\", errors=\"coerce\")\n",
    "df[\"sec_of_day\"] = ts.dt.hour*3600 + ts.dt.minute*60 + ts.dt.second\n",
    "\n",
    "# 4) Drop rows where either is NaN and compute correlation\n",
    "clean = df.dropna(subset=[\"mat_time\",\"sec_of_day\"])\n",
    "print(\"Pearson r:\", clean[\"mat_time\"].corr(clean[\"sec_of_day\"]))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(clean[\"sec_of_day\"], clean[\"mat_time\"], alpha=0.6)\n",
    "plt.xlabel(\"Seconds since midnight\")\n",
    "plt.ylabel(\"MATLAB time\")\n",
    "plt.title(\"MATLAB Time vs. Wall-clock Time\" + fn)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"mat_vs_time.png\", dpi=300, bbox_inches=\"tight\")\n",
    "print(\"Saved plot to mat_vs_time.png\")\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "predicting the MATLAB time for missing rows\n",
    "\n",
    "\"\"\"\n",
    "# --- 1) identify the .part2 block and fit a line mat_time = m*sec + b ---\n",
    "# flag all rows whose raw label contains “part2”\n",
    "mask_part2 = df[\"mat_raw\"].astype(str).str.contains(\"part2\", na=False)\n",
    "\n",
    "# x = wall-clock seconds, y = MATLAB time\n",
    "x = df.loc[mask_part2, \"sec_of_day\"]\n",
    "y = df.loc[mask_part2, \"mat_time\"]\n",
    "\n",
    "# fit a first-degree polynomial → slope m and intercept b\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "print(f\"part2 slope = {m:.4f}  intercept = {b:.1f}\")\n",
    "\n",
    "# --- 2) pick out the missing rows that belong to part2 (between first & last part2 secs) ---\n",
    "tmin, tmax = x.min(), x.max()\n",
    "mask_missing = (\n",
    "    (df[\"mat_raw\"] == \"missing\") &\n",
    "    df[\"sec_of_day\"].between(tmin, tmax)\n",
    ")\n",
    "\n",
    "r_part2 = x.corr(y)\n",
    "print(f\"Pearson r for .part2 = {r_part2:.3f}\")\n",
    "\n",
    "missing = df.loc[mask_missing, [\"ts_raw\", \"sec_of_day\"]].copy()\n",
    "# predict MATLAB time\n",
    "missing[\"pred_mat_time\"] = m * missing[\"sec_of_day\"] + b\n",
    "\n",
    "# --- 3) print your three estimates ---\n",
    "print(\"\\nPredicted MATLAB times for the missing .part2 rows:\")\n",
    "for ts, sec, pred in missing.itertuples(index=False):\n",
    "    print(f\"  {ts}  →  {pred:.0f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b2b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Cell 3\n",
    "code to convert from the csv files to the pkl format, with a different file for every different 'part' of each trial, so that there are 3/4 files per patient/day/task for patient 5\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from temporaldata import Interval\n",
    "\n",
    "# === Configuration ===\n",
    "# Sampling rate (samples per second) for converting sample indices to seconds\n",
    "FSAMPLE = 1200.0  # adjust to your data's sampling rate\n",
    "\n",
    "# === Paths ===\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "CSV_DIR = BASE_DIR  # CSV files live in the root of the project\n",
    "LABEL_DIR = os.path.join(BASE_DIR, \"processed_data\", \"labels\")\n",
    "os.makedirs(LABEL_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def process_csv(csv_path):\n",
    "    \"\"\"\n",
    "    Process a filtered symptom CSV and write Interval pickles per segment,\n",
    "    then print a brief preview of each Interval object.\n",
    "\n",
    "    Expects CSV with columns:\n",
    "      Matlab Time, Timestamp, Obsessions, Compulsions, Anxiety, Energy, Depression, Distress\n",
    "    \"\"\"\n",
    "    base = os.path.basename(csv_path).replace(\"_filtered_symptom_data.csv\", \"\")\n",
    "    print(f\"Processing file: {csv_path}\")\n",
    "\n",
    "    # Load CSV (header is first row)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Normalize column names: remove spaces, trim\n",
    "    df.columns = df.columns.str.strip().str.replace(' ', '')\n",
    "    total = len(df)\n",
    "    print(f\"  Total rows: {total}\")\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required = [\"MatlabTime\", \"Timestamp\", \"Obsessions\", \"Compulsions\",\n",
    "                \"Anxiety\", \"Energy\", \"Depression\", \"Distress\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns in {csv_path}: {missing}\")\n",
    "\n",
    "    # Extract numeric sample index from 'MatlabTime'\n",
    "    df['sample_idx'] = df['MatlabTime'].astype(str).str.extract(r\"^(\\d+)\")[0].astype(float)\n",
    "\n",
    "    # Determine segment label by splitting after the first hyphen\n",
    "    df['segment'] = df['MatlabTime'].astype(str).str.split('-', 1).str[1].str.strip()\n",
    "\n",
    "    # Compute interval start/end in seconds (60-second window)\n",
    "    ends = df['sample_idx'] / FSAMPLE\n",
    "    starts = (df['sample_idx'] - 60 * FSAMPLE) / FSAMPLE\n",
    "\n",
    "    # Stack rating columns into array (N x 6)\n",
    "    rating_cols = ['Obsessions', 'Compulsions', 'Anxiety', 'Energy', 'Depression', 'Distress']\n",
    "    ratings = df[rating_cols].astype(float).to_numpy()\n",
    "\n",
    "    # Default stim flag = 0 for all intervals\n",
    "    stim_arr = np.zeros((total,), dtype=int)\n",
    "    # Combine ratings + stim into label array (N x 7)\n",
    "    label_arr = np.hstack([ratings, stim_arr.reshape(-1, 1)])\n",
    "\n",
    "    # Write one Interval pickle per segment and preview\n",
    "    for segment, grp in df.groupby('segment'):\n",
    "        idx = grp.index\n",
    "        iv = Interval(\n",
    "            start=starts.iloc[idx].to_numpy(),\n",
    "            end=ends.iloc[idx].to_numpy(),\n",
    "            label=label_arr[idx],\n",
    "            timekeys=['start', 'end']\n",
    "        )\n",
    "        out_name = f\"{base}_{segment}_intervals.pkl\"\n",
    "        out_path = os.path.join(LABEL_DIR, out_name)\n",
    "        with open(out_path, 'wb') as pf:\n",
    "            pickle.dump(iv, pf)\n",
    "        print(f\"  → Segment '{segment}': {len(idx)} intervals saved to {out_path}\")\n",
    "        # Preview first three intervals\n",
    "        print(f\"    starts[:3]: {iv.start[:3]}\")\n",
    "        print(f\"    ends[:3]:   {iv.end[:3]}\")\n",
    "        print(f\"    labels[:3]: {iv.label[:3]}\")\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Only process Patient 4 CSV\n",
    "#     patient4_csv = os.path.join(CSV_DIR, 'Day4_02082025_filtered_symptom_data.csv')\n",
    "#     if os.path.exists(patient4_csv):\n",
    "#         process_csv(patient4_csv)\n",
    "#     else:\n",
    "#         raise FileNotFoundError(f\"Patient 4 CSV not found at {patient4_csv}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Process all *_filtered_symptom_data.csv files in the root directory\n",
    "    for fname in os.listdir(CSV_DIR):\n",
    "        if fname.endswith('_filtered_symptom_data.csv'):\n",
    "            process_csv(os.path.join(CSV_DIR, fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jmehrotra_ocd_venv)",
   "language": "python",
   "name": "jmehrotra_ocd_venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
